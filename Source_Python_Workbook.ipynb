{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d0de9d-d0db-439b-bdaa-5a82dde0f9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File heart_disease_uci.csv already present\n",
      "                     Accuracy       AUC  Precision    Recall  F1 Score  \\\n",
      "Logistic Regression  0.819672  0.928571   0.742857  0.928571  0.825397   \n",
      "Decision Tree        0.704918  0.708333   0.656250  0.750000  0.700000   \n",
      "KNN                  0.852459  0.916667   0.771429  0.964286  0.857143   \n",
      "Naive Bayes          0.540984  0.813853   0.500000  0.214286  0.300000   \n",
      "Random Forest        0.868852  0.938312   0.812500  0.928571  0.866667   \n",
      "XGBoost              0.819672  0.904762   0.774194  0.857143  0.813559   \n",
      "\n",
      "                          MCC  \n",
      "Logistic Regression  0.660870  \n",
      "Decision Tree        0.415768  \n",
      "KNN                  0.727393  \n",
      "Naive Bayes          0.040700  \n",
      "Random Forest        0.745142  \n",
      "XGBoost              0.642938  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import urllib.request\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# URL of the processed Cleveland dataset (most commonly used)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "\n",
    "# Save as CSV file\n",
    "output_file = \"Data/heart_disease_uci.csv\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(output_file):\n",
    "    print(\"File not found. Downloading...\")\n",
    "    urllib.request.urlretrieve(url, output_file)\n",
    "    print(\"Download complete! File saved as heart_disease_uci.csv\")\n",
    "else:\n",
    "    print(\"File heart_disease_uci.csv already present\")\n",
    "\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Load Dataset\n",
    "# ================================\n",
    "\n",
    "# Column names as per UCI documentation\n",
    "columns = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
    "    \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\"Data/heart_disease_uci.csv\", names=columns)\n",
    "\n",
    "data.head()\n",
    "\n",
    "# Remove missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Binary classification\n",
    "data[\"target\"] = (data[\"target\"] > 0).astype(int)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "# ================================\n",
    "# Train-Test Split\n",
    "# ================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Save raw test dataset BEFORE scaling\n",
    "X_test_raw = pd.DataFrame(X_test, columns=X.columns)\n",
    "X_test_raw[\"target\"] = y_test.values\n",
    "\n",
    "X_test_raw.to_csv(\"heart_test_final.csv\", index=False)\n",
    "\n",
    "# ================================\n",
    "# Feature Scaling\n",
    "# ================================\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ================================\n",
    "# Evaluation Function\n",
    "# ================================\n",
    "def evaluate(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    return [\n",
    "        accuracy_score(y_test, y_pred),\n",
    "        roc_auc_score(y_test, y_prob),\n",
    "        precision_score(y_test, y_pred),\n",
    "        recall_score(y_test, y_pred),\n",
    "        f1_score(y_test, y_pred),\n",
    "        matthews_corrcoef(y_test, y_pred)\n",
    "    ]\n",
    "\n",
    "# ================================\n",
    "# Models\n",
    "# ================================\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# Train & Evaluate\n",
    "# ================================\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    results[name] = evaluate(model)\n",
    "\n",
    "# ================================\n",
    "# Results Table\n",
    "# ================================\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    index=[\"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\"]\n",
    ").T\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Save scaler (VERY IMPORTANT)\n",
    "# ================================\n",
    "joblib.dump(scaler, \"Model/scaler.pkl\")\n",
    "\n",
    "# ================================\n",
    "# Save each trained model\n",
    "# ================================a\n",
    "for name, model in models.items():\n",
    "    # Create a safe filename\n",
    "    file_name = name.lower().replace(\" \", \"_\") + \".pkl\"\n",
    "    path = os.path.join(\"Model\", file_name)\n",
    "    \n",
    "    joblib.dump(model, path)\n",
    "    #print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d540d9c-6fc3-4b18-ab29-e9d0bf2dbec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4632539-6748-432d-bf94-b408201c5ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
